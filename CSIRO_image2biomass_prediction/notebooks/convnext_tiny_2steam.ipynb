{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2365684f",
   "metadata": {
    "papermill": {
     "duration": 0.003406,
     "end_time": "2025-12-19T14:21:03.827171",
     "exception": false,
     "start_time": "2025-12-19T14:21:03.823765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[This helped me a lot to learn also](https://www.kaggle.com/code/none00000/csiro)    <<-- Click Me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0052a44",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:03.833571Z",
     "iopub.status.busy": "2025-12-19T14:21:03.833257Z",
     "iopub.status.idle": "2025-12-19T14:21:18.872788Z",
     "shell.execute_reply": "2025-12-19T14:21:18.871964Z"
    },
    "papermill": {
     "duration": 15.044418,
     "end_time": "2025-12-19T14:21:18.874208",
     "exception": false,
     "start_time": "2025-12-19T14:21:03.829790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from albumentations import Compose, Resize, Normalize, HorizontalFlip, VerticalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3fdb44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:18.880956Z",
     "iopub.status.busy": "2025-12-19T14:21:18.880201Z",
     "iopub.status.idle": "2025-12-19T14:21:18.925305Z",
     "shell.execute_reply": "2025-12-19T14:21:18.924760Z"
    },
    "papermill": {
     "duration": 0.04946,
     "end_time": "2025-12-19T14:21:18.926325",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.876865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    SEED = 67\n",
    "\n",
    "    TRAIN_PATH = '/kaggle/input/csiro-biomass/train.csv'\n",
    "    TEST_PATH =  '/kaggle/input/csiro-biomass/test.csv'\n",
    "    MODEL_NAME = 'convnext_tiny'\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    BATCH_SIZE =  4\n",
    "    NUM_WORKERS = 2\n",
    "    N_FOLDS = 5\n",
    "    EPOCHS = 30\n",
    "\n",
    "    FREEZE_EPOCHS = EPOCHS // 3\n",
    "    LEARNING_RATE = 1e-4\n",
    "    FINETUNE_LR = 1e-5\n",
    "\n",
    "    \n",
    "    loss_weights = {\n",
    "        \"Dry_Green_g\": 0.2,\n",
    "        \"Dry_Total_g\": 0.5,\n",
    "        \"GDM_g\": 0.3\n",
    "    }\n",
    "\n",
    "    weights = {\n",
    "        \"Dry_Clover_g\": 0.1,\n",
    "        \"Dry_Dead_g\": 0.1,\n",
    "        \"Dry_Green_g\": 0.1,\n",
    "        \"Dry_Total_g\": 0.5,\n",
    "        \"GDM_g\": 0.2\n",
    "    }\n",
    "\n",
    "    IMG_SIZE = 768\n",
    "\n",
    "cfg = CONFIG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8a6e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:18.932533Z",
     "iopub.status.busy": "2025-12-19T14:21:18.932050Z",
     "iopub.status.idle": "2025-12-19T14:21:18.936656Z",
     "shell.execute_reply": "2025-12-19T14:21:18.936059Z"
    },
    "papermill": {
     "duration": 0.008753,
     "end_time": "2025-12-19T14:21:18.937670",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.928917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self):\n",
    "        self.pipeline = self.__make_pipeline()\n",
    "\n",
    "    def __make_pipeline(self):\n",
    "        base_transforms = [\n",
    "            Resize(cfg.IMG_SIZE, cfg.IMG_SIZE),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ]\n",
    "\n",
    "        original_view = Compose([\n",
    "            *base_transforms\n",
    "        ])\n",
    "\n",
    "        hflip_view = Compose([\n",
    "            HorizontalFlip(p=1.0),\n",
    "            *base_transforms\n",
    "        ])\n",
    "\n",
    "        vflip_view = Compose([\n",
    "            VerticalFlip(p=1.0),\n",
    "            *base_transforms\n",
    "        ])\n",
    "        \n",
    "        return [original_view, hflip_view, vflip_view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111ba6ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:18.943607Z",
     "iopub.status.busy": "2025-12-19T14:21:18.942969Z",
     "iopub.status.idle": "2025-12-19T14:21:18.949036Z",
     "shell.execute_reply": "2025-12-19T14:21:18.948527Z"
    },
    "papermill": {
     "duration": 0.009984,
     "end_time": "2025-12-19T14:21:18.950001",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.940017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, train=True):\n",
    "        self.train = train\n",
    "        self.df = df\n",
    "\n",
    "        if not transform:\n",
    "            # pick the base pipeline\n",
    "            self.transform = Transform().pipeline[0]\n",
    "        else:\n",
    "            self.transform = transform\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df['image_path'].iloc[idx]\n",
    "        img = np.array(Image.open(f'/kaggle/input/csiro-biomass/{path}').convert(\"RGB\"))\n",
    "\n",
    "        mid = img.shape[0] // 2\n",
    "        left, right = img[:, :mid], img[:, mid:]\n",
    "        \n",
    "        transform_left = self.transform(image=left)['image']\n",
    "        transform_right = self.transform(image=right)['image']\n",
    "        \n",
    "        if self.train:\n",
    "            targets = torch.tensor(self.df[['Dry_Green_g', 'Dry_Total_g', 'GDM_g']].iloc[idx].to_numpy(), dtype=torch.float)\n",
    "            all_targets = torch.tensor(self.df[['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']].iloc[idx].to_numpy(), dtype=torch.float)\n",
    "            return transform_left, transform_right, targets, all_targets\n",
    "        else:\n",
    "            return transform_left, transform_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc62fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:18.955778Z",
     "iopub.status.busy": "2025-12-19T14:21:18.955348Z",
     "iopub.status.idle": "2025-12-19T14:21:18.960546Z",
     "shell.execute_reply": "2025-12-19T14:21:18.959985Z"
    },
    "papermill": {
     "duration": 0.009239,
     "end_time": "2025-12-19T14:21:18.961675",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.952436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_r2_torch(y_true, y_pred, w):\n",
    "    w = torch.tensor(list(w.values()), dtype=torch.float32)\n",
    "    w = w / w.sum()\n",
    "    \n",
    "    y_bar = (w * y_true).sum(dim=1, keepdim=True)\n",
    "    ss_res = (w * (y_true - y_pred) ** 2).sum()\n",
    "    ss_tot = (w * (y_true - y_bar) ** 2).sum()\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "def competition_score(all_preds_3, all_targets_5):\n",
    "    pred_green = all_preds_3['green']\n",
    "    pred_total = all_preds_3['total']\n",
    "    pred_gdm = all_preds_3['gdm']\n",
    "\n",
    "    pred_clover = np.maximum(0, pred_gdm - pred_green)\n",
    "    pred_dead = np.maximum(0, pred_total - pred_gdm)\n",
    "\n",
    "    y_preds = np.stack([\n",
    "        pred_clover,\n",
    "        pred_dead,\n",
    "        pred_green,\n",
    "        pred_total,\n",
    "        pred_gdm\n",
    "    ], axis=1)\n",
    "\n",
    "    y_true = all_targets_5\n",
    "\n",
    "    r2_scores = r2_score(y_true, y_preds, multioutput='raw_values')\n",
    "\n",
    "    weighted_r2_total = 0.0\n",
    "    for i, weight in enumerate(cfg.weights.values()):\n",
    "        weighted_r2_total += r2_scores[i] * weight\n",
    "\n",
    "    return weighted_r2_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c873b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:18.967489Z",
     "iopub.status.busy": "2025-12-19T14:21:18.967082Z",
     "iopub.status.idle": "2025-12-19T14:21:18.970928Z",
     "shell.execute_reply": "2025-12-19T14:21:18.970432Z"
    },
    "papermill": {
     "duration": 0.007713,
     "end_time": "2025-12-19T14:21:18.971905",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.964192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_ids(data):\n",
    "    return data.split('__')[0]\n",
    "    \n",
    "def preprocessing(data):\n",
    "    data['sample_id'] = data['sample_id'].apply(clean_ids)\n",
    "\n",
    "    if 'target' in data.columns:\n",
    "        return data.pivot_table(\n",
    "            index=[\n",
    "                'sample_id',\n",
    "                'image_path'\n",
    "            ],\n",
    "                columns='target_name', \n",
    "                values='target'\n",
    "            ).reset_index()\n",
    "\n",
    "    data = data[['sample_id', 'image_path']]\n",
    "    return data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ec0dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:18.977671Z",
     "iopub.status.busy": "2025-12-19T14:21:18.977211Z",
     "iopub.status.idle": "2025-12-19T14:21:18.983429Z",
     "shell.execute_reply": "2025-12-19T14:21:18.982879Z"
    },
    "papermill": {
     "duration": 0.010248,
     "end_time": "2025-12-19T14:21:18.984456",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.974208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BioModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, n_targets=3, drop_rate=0.3):\n",
    "        super(BioModel, self).__init__()\n",
    "        self.backbone =  timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "\n",
    "        self.n_features = self.backbone.num_features\n",
    "        self.n_combined_features = self.n_features * 2\n",
    "\n",
    "        \n",
    "        self.head_total = nn.Sequential(\n",
    "            nn.Linear(self.n_combined_features, self.n_combined_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.n_combined_features // 2, 1) \n",
    "        )\n",
    "\n",
    "        self.head_gdm = nn.Sequential(\n",
    "            nn.Linear(self.n_combined_features, self.n_combined_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.n_combined_features // 2, 1) \n",
    "        )\n",
    "        \n",
    "        self.head_green = nn.Sequential(\n",
    "            nn.Linear(self.n_combined_features, self.n_combined_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.n_combined_features // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, left, right):\n",
    "        features_left = self.backbone(left)\n",
    "        features_right = self.backbone(right)\n",
    "\n",
    "        combined = torch.cat([features_left, features_right], dim=1)\n",
    "        out_total = self.head_total(combined)\n",
    "        out_gdm = self.head_gdm(combined)\n",
    "        out_green = self.head_green(combined)\n",
    "\n",
    "        return out_green, out_total, out_gdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b9299c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:18.990065Z",
     "iopub.status.busy": "2025-12-19T14:21:18.989663Z",
     "iopub.status.idle": "2025-12-19T14:21:18.994437Z",
     "shell.execute_reply": "2025-12-19T14:21:18.993884Z"
    },
    "papermill": {
     "duration": 0.008561,
     "end_time": "2025-12-19T14:21:18.995330",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.986769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightedLoss(nn.Module):\n",
    "    def __init__(self, loss_weights_dict):\n",
    "        super(WeightedLoss, self).__init__()\n",
    "        \n",
    "        self.criterion = nn.SmoothL1Loss()\n",
    "        self.weights = loss_weights_dict\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        pred_green, pred_total, pred_gdm = predictions\n",
    "\n",
    "        true_green = targets[:, 0].unsqueeze(-1)\n",
    "        true_total   = targets[:, 1].unsqueeze(-1)\n",
    "        true_gdm = targets[:, 2].unsqueeze(-1)\n",
    "\n",
    "        loss_total = self.criterion(pred_total, true_total)\n",
    "        loss_gdm   = self.criterion(pred_gdm, true_gdm)\n",
    "        loss_green = self.criterion(pred_green, true_green)\n",
    "\n",
    "        total_loss = (\n",
    "            self.weights['Dry_Green_g'] * loss_green +\n",
    "            self.weights['GDM_g'] * loss_gdm +\n",
    "            self.weights['Dry_Total_g'] * loss_total\n",
    "        )\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a5e0d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:19.001012Z",
     "iopub.status.busy": "2025-12-19T14:21:19.000587Z",
     "iopub.status.idle": "2025-12-19T14:21:19.006066Z",
     "shell.execute_reply": "2025-12-19T14:21:19.005554Z"
    },
    "papermill": {
     "duration": 0.009397,
     "end_time": "2025-12-19T14:21:19.007053",
     "exception": false,
     "start_time": "2025-12-19T14:21:18.997656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, verbose=False, filename='fold'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.filename = filename\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.filename)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd294e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:19.013302Z",
     "iopub.status.busy": "2025-12-19T14:21:19.012580Z",
     "iopub.status.idle": "2025-12-19T14:21:19.069460Z",
     "shell.execute_reply": "2025-12-19T14:21:19.068906Z"
    },
    "papermill": {
     "duration": 0.061127,
     "end_time": "2025-12-19T14:21:19.070540",
     "exception": false,
     "start_time": "2025-12-19T14:21:19.009413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(cfg.TRAIN_PATH)\n",
    "train = preprocessing(train)\n",
    "train['fold'] = -1\n",
    "\n",
    "# test = pd.read_csv(cfg.TEST_PATH)\n",
    "# test = preprocessing(test)\n",
    "if len(train) > 100:\n",
    "    num_bins = 10\n",
    "\n",
    "train['total_bin'] = pd.cut(train['Dry_Total_g'], bins=num_bins, labels=False)\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=cfg.N_FOLDS, \n",
    "    shuffle=True, \n",
    "    random_state=cfg.SEED\n",
    ")\n",
    "\n",
    "for fold_num, (train_idx, valid_idx) in enumerate(skf.split(train, train['total_bin'])):\n",
    "    train.loc[valid_idx, 'fold'] = fold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "666e701c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:19.075987Z",
     "iopub.status.busy": "2025-12-19T14:21:19.075797Z",
     "iopub.status.idle": "2025-12-19T14:21:19.083074Z",
     "shell.execute_reply": "2025-12-19T14:21:19.082600Z"
    },
    "papermill": {
     "duration": 0.011169,
     "end_time": "2025-12-19T14:21:19.084047",
     "exception": false,
     "start_time": "2025-12-19T14:21:19.072878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device=cfg.device):\n",
    "    model.train()  \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    for (img_left, img_right, train_targets, _all_targets_ignored) in pbar:\n",
    "        \n",
    "        img_left = img_left.to(device)\n",
    "        img_right = img_right.to(device)\n",
    "        targets = train_targets.to(device)\n",
    "        \n",
    "        predictions = model(img_left, img_right)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(predictions, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "        \n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device=cfg.device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    all_preds_3 = {'total': [], 'gdm': [], 'green': []}\n",
    "    all_targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validating\", leave=False)\n",
    "        for (img_left, img_right, train_targets, all_targets) in pbar:\n",
    "            \n",
    "            img_left = img_left.to(device)\n",
    "            img_right = img_right.to(device)\n",
    "            train_targets = train_targets.to(device)\n",
    "            \n",
    "            pred_green, pred_total, pred_gdm = model(img_left, img_right)\n",
    "            \n",
    "            predictions_tuple = (pred_total, pred_gdm, pred_green)\n",
    "            loss = criterion(predictions_tuple, train_targets)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            all_preds_3['total'].append(pred_total.cpu().numpy())\n",
    "            all_preds_3['gdm'].append(pred_gdm.cpu().numpy())\n",
    "            all_preds_3['green'].append(pred_green.cpu().numpy())\n",
    "            all_targets_list.append(all_targets.cpu().numpy())\n",
    "\n",
    "\n",
    "    preds_dict_np = {\n",
    "        'total': np.concatenate(all_preds_3['total']).flatten(),\n",
    "        'gdm':   np.concatenate(all_preds_3['gdm']).flatten(),\n",
    "        'green': np.concatenate(all_preds_3['green']).flatten()\n",
    "    }\n",
    "    targets_np_5 = np.concatenate(all_targets_list)\n",
    "    \n",
    "    score = competition_score(preds_dict_np, targets_np_5)\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / len(loader)\n",
    "    \n",
    "    return avg_epoch_loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f5fb69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:19.089735Z",
     "iopub.status.busy": "2025-12-19T14:21:19.089449Z",
     "iopub.status.idle": "2025-12-19T14:21:19.101095Z",
     "shell.execute_reply": "2025-12-19T14:21:19.100575Z"
    },
    "papermill": {
     "duration": 0.01576,
     "end_time": "2025-12-19T14:21:19.102082",
     "exception": false,
     "start_time": "2025-12-19T14:21:19.086322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_fold(fold):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" Fold: {fold}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_df = train[train['fold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    index = fold % 3\n",
    "    pipeline = Transform().pipeline[index]\n",
    "\n",
    "    print(f'\\nChoosing pipeline {\"simple\" if (index == 0) else (\"horizontal\" if (index == 1) else \"vertical\")}')\n",
    "    \n",
    "    train_dataset = BiomassDataset(train_df, pipeline)\n",
    "    valid_dataset = BiomassDataset(valid_df)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "        num_workers=cfg.NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=cfg.BATCH_SIZE * 2, shuffle=False,\n",
    "        num_workers=cfg.NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"MODEL:  '{cfg.MODEL_NAME}'...\")\n",
    "    model_base = BioModel(cfg.MODEL_NAME, cfg.MODEL_NAME)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\" {torch.cuda.device_count()} GPU avilable\")\n",
    "        model = nn.DataParallel(model_base)\n",
    "    else:\n",
    "        model = model_base\n",
    "        \n",
    "    model.to(cfg.device)\n",
    "    \n",
    "    criterion = WeightedLoss(cfg.loss_weights).to(cfg.device)\n",
    "    \n",
    "    print(f\"Epochs: {cfg.EPOCHS} | FREEZE : {cfg.FREEZE_EPOCHS} | LR: {cfg.LEARNING_RATE}\")\n",
    "\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        lr=cfg.LEARNING_RATE\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.1, patience=2 \n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(filename=f'{cfg.MODEL_NAME}_fold_{fold}.pt')\n",
    "\n",
    "    for epoch in range(1,  cfg.EPOCHS - cfg.FREEZE_EPOCHS + 1):\n",
    "        print(f\"\\n--- Epoch {epoch}/{cfg.EPOCHS} ---\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        valid_loss, score = validate_one_epoch(model, valid_loader, criterion)\n",
    "        \n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f} | Score (R^2): {score:.4f}\")\n",
    "        \n",
    "        early_stop(score, model)\n",
    "        if early_stop.early_stop:\n",
    "            print(f'Stopping training on epoch {epoch} with best score {np.abs(early_stop.best_score)}')\n",
    "            break\n",
    "        \n",
    "    print(f\"\\n--- Fine-tuning  ---\")\n",
    "    print(f\"Epochs: {cfg.EPOCHS - cfg.FREEZE_EPOCHS + 1}/{cfg.EPOCHS} | LR: {cfg.FINETUNE_LR}\")\n",
    "\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=cfg.FINETUNE_LR\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.2, patience=3\n",
    "    )\n",
    "\n",
    "    early_stop.early_stop = False\n",
    "    \n",
    "    for epoch in range((cfg.EPOCHS - cfg.FREEZE_EPOCHS + 1), cfg.EPOCHS + 1):\n",
    "        print(f\"\\n--- Epoch {epoch}/{cfg.EPOCHS} ---\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        valid_loss, score = validate_one_epoch(model, valid_loader, criterion)\n",
    "        \n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f} | Score (R^2): {score:.4f}\")\n",
    "        \n",
    "        early_stop(score, model)\n",
    "        if early_stop.early_stop:\n",
    "            print(f'Stopping training on epoch {epoch} with best score {np.abs(early_stop.best_score)}')\n",
    "            break\n",
    "            \n",
    "    end_time = time.time()\n",
    "    best_score = np.abs(early_stop.best_score)\n",
    "    print(f\"\\nFold {fold} runs in  {(end_time - start_time)/60:.2f}\")\n",
    "    print(f\"Best Score : {best_score:.4f}\")\n",
    "    \n",
    "    del model, train_loader, valid_loader, train_dataset, valid_dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f11194d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:21:19.107615Z",
     "iopub.status.busy": "2025-12-19T14:21:19.107188Z",
     "iopub.status.idle": "2025-12-19T14:21:19.109697Z",
     "shell.execute_reply": "2025-12-19T14:21:19.109194Z"
    },
    "papermill": {
     "duration": 0.006367,
     "end_time": "2025-12-19T14:21:19.110704",
     "exception": false,
     "start_time": "2025-12-19T14:21:19.104337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     for i in range(cfg.N_FOLDS):\n",
    "#         run_fold(i)\n",
    "# except Exception as e:\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     raise e"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.443068,
   "end_time": "2025-12-19T14:21:20.833323",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-19T14:21:00.390255",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
