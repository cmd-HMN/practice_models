{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13059803,"sourceType":"datasetVersion","datasetId":8264672}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split, KFold\nfrom catboost import CatBoostClassifier as cbc\nimport catboost as cb\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:06:54.736775Z","iopub.execute_input":"2025-11-25T15:06:54.737093Z","iopub.status.idle":"2025-11-25T15:07:07.288261Z","shell.execute_reply.started":"2025-11-25T15:06:54.737060Z","shell.execute_reply":"2025-11-25T15:07:07.287019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CONFIG:\n    seed = 67\n    train_path = '/kaggle/input/playground-series-s5e11/train.csv'\n    test_path = '/kaggle/input/playground-series-s5e11/test.csv'\n    orig_path = '/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv'\n\n    columns = ['annual_income',\n         'debt_to_income_ratio',\n         'credit_score',\n         'loan_amount',\n         'interest_rate',\n         'gender',\n         'marital_status',\n         'education_level',\n         'employment_status',\n         'loan_purpose',\n         'grade_subgrade']\n\n    CATS = ['gender','marital_status','education_level','employment_status','loan_purpose','grade_subgrade']\n    NUMS = ['annual_income',\n         'debt_to_income_ratio',\n         'credit_score',\n         'loan_amount',\n         'interest_rate']\n    TARGET = 'loan_paid_back'\n\n\n    # feature engineering\n    agg_funcs = ['mean', 'std', 'min', 'max', 'median']\n\n\n    # training\n    N_SPLITS = 5\n\ncfg = CONFIG()\n\n\ndef print_with_design(statement):\n    print('='* 40)\n    print(statement)\n    print('='* 40, '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:07:23.976170Z","iopub.execute_input":"2025-11-25T15:07:23.976516Z","iopub.status.idle":"2025-11-25T15:07:23.983879Z","shell.execute_reply.started":"2025-11-25T15:07:23.976491Z","shell.execute_reply":"2025-11-25T15:07:23.982768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def import_data(sep_ids=True):\n    print_with_design('1. IMPORTING DATA')\n    train = pd.read_csv(cfg.train_path)\n    test = pd.read_csv(cfg.test_path)\n    orig = pd.read_csv(cfg.orig_path)\n\n    output = (train, orig, test)\n    \n    if sep_ids:\n        train = train.drop('id', axis=1)\n        test_ids = test['id']\n        test = test.drop('id', axis=1)\n        output = (train , orig, test, test_ids)\n\n    print(f'Imported train data {train.shape}')\n    print(f'Imported test data {test.shape}', end='\\n')\n\n    return output\n\ntrain, orig, test, test_ids = import_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:07:24.364125Z","iopub.execute_input":"2025-11-25T15:07:24.364478Z","iopub.status.idle":"2025-11-25T15:07:26.454575Z","shell.execute_reply.started":"2025-11-25T15:07:24.364452Z","shell.execute_reply":"2025-11-25T15:07:26.453511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"[idea inspired by \\[Click me\\]](https://www.kaggle.com/code/rohanrathod02/predicting-loan-payback-eda-adv-fe-ensemble#3.-Feature-Engineering-&-Preprocessing)","metadata":{}},{"cell_type":"code","source":"def feature_enginering(train: pd.DataFrame, orig: pd.DataFrame, test: pd.DataFrame):\n    print_with_design(f'2. Feature Engineering')\n\n    print(f\"Target variable: '{cfg.TARGET}'\")\n    print(f\"Total base features (excluding 'id' and target): {len(cfg.columns)} columns\")\n    print(f\"Categorical base features used for engineering: {len(cfg.CATS)} columns\")\n    print(f\"Numerical base features: {len(cfg.NUMS)} columns\")\n    initial_cols = len(train.columns)\n\n    print(\"\\n--- Creating Orig-based Statistical Features ---\\n\")\n\n    for col in cfg.columns:\n        print(f'- Performing Operations on {col}')\n        if col not in orig.columns:\n            print(f\"Warning: Column '{col}' from BASE not found in df_orig. Skipping feature creation for this column.\")\n            continue\n    \n        stats_df = orig.groupby(col)[cfg.TARGET].agg(cfg.agg_funcs).reset_index()\n\n        new_stat_col_names = [f'orig_{func}_{col}' for func in cfg.agg_funcs]\n        stats_df.columns = [col] + new_stat_col_names\n\n        train = train.merge(stats_df, on=col, how='left')\n        test = test.merge(stats_df, on=col, how='left')\n\n        counts_df = orig[col].value_counts().reset_index(name=f'orig_count_{col}')\n        counts_df.columns = [col, f'orig_count_{col}']\n\n        train = train.merge(counts_df, on=col, how='left')\n        test = test.merge(counts_df, on=col, how='left')\n\n    print(\"\\n--- Feature Creation Summary ---\\n\")\n    print(f\"Number of new features added: {(len(train.columns) - initial_cols)}\")\n    print(f\"Updated shape of train: {train.shape}\\n\")\n    print(f\"Updated shape of test: {test.shape}\\n\")\n\n    return train, test\n\n\ndef advanced_features(df):\n    target = True\n    if cfg.TARGET not in df.columns:\n        target = False\n    \n    print_with_design(f'3-{\"1\" if target else \"2\"}. Advance Feature Engineering on {\"train\" if target else \"test\"}')\n    print('\\n - Core affordability')\n    df['income_loan_ratio'] = df['annual_income'] / (df['loan_amount'] + 1)\n    df['loan_to_income'] = df['loan_amount'] / (df['annual_income'] + 1)\n\n    print('- Debt metrics')\n    df['total_debt'] = df['debt_to_income_ratio'] * df['annual_income']\n    df['available_income'] = df['annual_income'] * (1 - df['debt_to_income_ratio'])\n    df['debt_burden'] = df['debt_to_income_ratio'] * df['loan_amount']\n\n    print('- Payment analysis')\n    df['monthly_payment'] = df['loan_amount'] * df['interest_rate'] / 1200\n    df['payment_to_income'] = df['monthly_payment'] / (df['annual_income'] / 12 + 1)\n    df['affordability'] = df['available_income'] / (df['loan_amount'] + 1)\n\n    print('- Risk scoring')\n    df['default_risk'] = (df['debt_to_income_ratio'] * 0.40 +\n                          (850 - df['credit_score']) / 850 * 0.35 +\n                          df['interest_rate'] / 100 * 0.25)\n\n    print('- Credit analysis')\n    df['credit_utilization'] = df['credit_score'] * (1 - df['debt_to_income_ratio'])\n    df['credit_interest_product'] = df['credit_score'] * df['interest_rate'] / 100\n\n    print('- Log transformations')\n    for col in ['annual_income', 'loan_amount']:\n        df[f'{col}_log'] = np.log1p(df[col])\n\n    print('- Grade parsing')\n    df['grade_letter'] = df['grade_subgrade'].str[0]\n    df['grade_number'] = df['grade_subgrade'].str[1].astype(int)\n    grade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n    df['grade_rank'] = df['grade_letter'].map(grade_map)\n\n    print(f'\\n Completed Feature Engineering part for the {\"train\" if target else \"test\"}\\n')\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:07:26.733861Z","iopub.execute_input":"2025-11-25T15:07:26.734164Z","iopub.status.idle":"2025-11-25T15:07:26.750464Z","shell.execute_reply.started":"2025-11-25T15:07:26.734141Z","shell.execute_reply":"2025-11-25T15:07:26.749339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train, test = feature_enginering(train, orig, test)\ntrain = advanced_features(train)\ntest = advanced_features(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:07:27.000404Z","iopub.execute_input":"2025-11-25T15:07:27.000839Z","iopub.status.idle":"2025-11-25T15:07:35.790486Z","shell.execute_reply.started":"2025-11-25T15:07:27.000809Z","shell.execute_reply":"2025-11-25T15:07:35.789391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocessing(train, test):\n    print_with_design('4. Preprocessing')\n\n    print(\"\\n--- Making Categorial Columns ---\\n\")\n    cols = train.select_dtypes(['object']).columns\n    for col in cols:\n        print(f'- {col}')\n        train[col] = train[col].astype('category')\n        test[col] = test[col].astype('category')\n\n    print('\\nComplete Preprocessing\\n')\n    return train, test, cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:07:35.792931Z","iopub.execute_input":"2025-11-25T15:07:35.793603Z","iopub.status.idle":"2025-11-25T15:07:35.799866Z","shell.execute_reply.started":"2025-11-25T15:07:35.793569Z","shell.execute_reply":"2025-11-25T15:07:35.798617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train, test, cat_cols = preprocessing(train, test)\ncat_cols = list(cat_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:07:35.801031Z","iopub.execute_input":"2025-11-25T15:07:35.801395Z","iopub.status.idle":"2025-11-25T15:07:36.253564Z","shell.execute_reply.started":"2025-11-25T15:07:35.801364Z","shell.execute_reply":"2025-11-25T15:07:36.252086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = (train, test)\nmodels = {\n    'model_1': {\n        'name': 'LightGBM',\n        'params': {\n            'objective': 'cross_entropy',\n            'metric': 'auc',\n            'n_estimators': 2000,\n            'boosting_type': 'gbdt',\n            'learning_rate': 0.01,\n            'num_leaves': 50,\n            'max_depth': 6,\n            'min_child_samples': 20,\n            'subsample': 0.8,\n            'subsample_freq': 1,\n            'colsample_bytree': 0.8,\n            'reg_alpha': 0.05,\n            'reg_lambda': 0.1,\n            'min_split_gain': 0.01,\n            'random_state': cfg.seed,\n            'device': 'cpu',\n            'verbose': -1\n        }\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:07:36.255497Z","iopub.execute_input":"2025-11-25T15:07:36.255847Z","iopub.status.idle":"2025-11-25T15:07:36.262915Z","shell.execute_reply.started":"2025-11-25T15:07:36.255821Z","shell.execute_reply":"2025-11-25T15:07:36.261566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(data, model, cat_cols):\n    name = model['name']\n    print_with_design(f'Training Model -- {name}')\n\n    train, test = data\n\n    kf = KFold(n_splits=cfg.N_SPLITS, shuffle=True, random_state=cfg.seed)\n    X = train.drop(cfg.TARGET, axis=1)\n    y = train[cfg.TARGET]\n\n    oof_preds = np.zeros(train.shape[0])\n    test_preds = np.zeros(test.shape[0])\n    train_errors = []\n    val_errors = []\n    for fold, (tr, va) in enumerate(kf.split(X, y), 1):\n        print(f'\\n-- Fold {fold} --\\n')\n        \n        X_train = X.iloc[tr]\n        y_train = y[tr]\n        X_val = X.iloc[va]\n        y_val = y[va]\n        \n        if name == 'LightGBM':\n            lgb_dataset = lgb.Dataset(X_train, y_train, categorical_feature=cat_cols)\n            tr_model = lgb.train(train_set=lgb_dataset, params=model['params'])\n        elif name == 'CatBoost':\n            tr_model = CatBoostClassifier(**model['params'])\n        else:\n            tr_model = XGBoostClassifer(**model['params'])\n\n        train_preds = tr_model.predict(X_train)\n        train_error = roc_auc_score(y_train, train_preds)\n        \n        val_error = roc_auc_score(y_val, tr_model.predict(X_val))\n\n        train_errors.append(train_error)\n        val_errors.append(val_error)\n        oof_preds[tr] = train_preds\n\n        test_preds += tr_model.predict(test)\n\n        print(f'- Train Error {train_error:.6f}')\n        print(f'- Val Error {val_error:.6f}\\n')\n\n    test_preds = test_preds/(kf.get_n_splits())\n\n    print_with_design('MEAN OF ERRORS')\n    print(f'- Train Error {np.mean(train_error):.6f}')\n    print(f'- Val Error {np.mean(val_error):.6f}\\n')\n\n    del tr_model, kf, X, y, X_train, X_val, y_train, y_val, train_preds\n    gc.collect()\n    \n    return oof_preds, test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:09:17.724902Z","iopub.execute_input":"2025-11-25T15:09:17.725259Z","iopub.status.idle":"2025-11-25T15:09:17.737085Z","shell.execute_reply.started":"2025-11-25T15:09:17.725232Z","shell.execute_reply":"2025-11-25T15:09:17.736119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oof_preds, test_preds = train_model(data, models['model_1'], cat_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:09:18.042020Z","iopub.execute_input":"2025-11-25T15:09:18.042356Z","iopub.status.idle":"2025-11-25T15:10:29.181588Z","shell.execute_reply.started":"2025-11-25T15:09:18.042331Z","shell.execute_reply":"2025-11-25T15:10:29.180199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def submit_test(test_ids=test_ids, test_preds=test_preds):\n    output = pd.DataFrame({\n        'id': test_ids,\n        cfg.TARGET: test_preds\n    })\n\n    output.to_csv('submission.csv', index=False)\n    return output.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:12:51.108930Z","iopub.execute_input":"2025-11-25T15:12:51.109335Z","iopub.status.idle":"2025-11-25T15:12:51.115811Z","shell.execute_reply.started":"2025-11-25T15:12:51.109310Z","shell.execute_reply":"2025-11-25T15:12:51.114447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submit_test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T15:13:01.607592Z","iopub.execute_input":"2025-11-25T15:13:01.607935Z","iopub.status.idle":"2025-11-25T15:13:02.338581Z","shell.execute_reply.started":"2025-11-25T15:13:01.607913Z","shell.execute_reply":"2025-11-25T15:13:02.337425Z"}},"outputs":[],"execution_count":null}]}